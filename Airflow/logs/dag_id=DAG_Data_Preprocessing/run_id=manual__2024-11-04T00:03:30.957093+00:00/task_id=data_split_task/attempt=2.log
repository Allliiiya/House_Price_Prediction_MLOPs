[2024-11-04T00:08:44.350+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: DAG_Data_Preprocessing.data_split_task manual__2024-11-04T00:03:30.957093+00:00 [queued]>
[2024-11-04T00:08:44.355+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: DAG_Data_Preprocessing.data_split_task manual__2024-11-04T00:03:30.957093+00:00 [queued]>
[2024-11-04T00:08:44.355+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2024-11-04T00:08:44.355+0000] {taskinstance.py:1280} INFO - Starting attempt 2 of 2
[2024-11-04T00:08:44.355+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2024-11-04T00:08:44.361+0000] {taskinstance.py:1300} INFO - Executing <Task(PythonOperator): data_split_task> on 2024-11-04 00:03:30.957093+00:00
[2024-11-04T00:08:44.365+0000] {standard_task_runner.py:55} INFO - Started process 544 to run task
[2024-11-04T00:08:44.367+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'DAG_Data_Preprocessing', 'data_split_task', 'manual__2024-11-04T00:03:30.957093+00:00', '--job-id', '158', '--raw', '--subdir', 'DAGS_FOLDER/***dag.py', '--cfg-path', '/tmp/tmpsigkaxne']
[2024-11-04T00:08:44.368+0000] {standard_task_runner.py:83} INFO - Job 158: Subtask data_split_task
[2024-11-04T00:08:44.393+0000] {task_command.py:388} INFO - Running <TaskInstance: DAG_Data_Preprocessing.data_split_task manual__2024-11-04T00:03:30.957093+00:00 [running]> on host b77d411e2e76
[2024-11-04T00:08:44.422+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=House_Price_Prediction Team
AIRFLOW_CTX_DAG_ID=DAG_Data_Preprocessing
AIRFLOW_CTX_TASK_ID=data_split_task
AIRFLOW_CTX_EXECUTION_DATE=2024-11-04T00:03:30.957093+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-11-04T00:03:30.957093+00:00
[2024-11-04T00:08:44.422+0000] {airflowdag.py:141} INFO - encoded_result
[2024-11-04T00:08:44.442+0000] {taskinstance.py:1768} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 192, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/airflowdag.py", line 147, in split_data_callable
    split_result = split_data(data, test_size=0.15)
  File "/opt/airflow/dags/src/data_splitting.py", line 16, in split_data
    df = pd.read_json(encoded_data)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 207, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/util/_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/json/_json.py", line 607, in read_json
    encoding_errors=encoding_errors,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/json/_json.py", line 675, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/json/_json.py", line 718, in _get_data_from_filepath
    errors=self.encoding_errors,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 614, in get_handle
    storage_options=storage_options,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/common.py", line 396, in _get_filepath_or_buffer
    raise ValueError(msg)
ValueError: Invalid file path or buffer object type: <class 'tuple'>
[2024-11-04T00:08:44.446+0000] {taskinstance.py:1323} INFO - Marking task as FAILED. dag_id=DAG_Data_Preprocessing, task_id=data_split_task, execution_date=20241104T000330, start_date=20241104T000844, end_date=20241104T000844
[2024-11-04T00:08:44.451+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 158 for task data_split_task (Invalid file path or buffer object type: <class 'tuple'>; 544)
[2024-11-04T00:08:44.464+0000] {local_task_job.py:208} INFO - Task exited with return code 1
[2024-11-04T00:08:44.477+0000] {taskinstance.py:2578} INFO - 0 downstream tasks scheduled from follow-on schedule check
